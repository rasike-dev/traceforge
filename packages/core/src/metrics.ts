import { metrics } from '@opentelemetry/api';

const meter = metrics.getMeter('traceforge.core', '0.1.0');

/**
 * Standard histogram boundaries for Datadog
 * latency_ms: 10, 50, 100, 300, 500, 1000, 3000, 10000
 * cost.usd: 0.001, 0.01, 0.05, 0.1, 0.5, 1, 5
 */
const LATENCY_BUCKETS = [10, 50, 100, 300, 500, 1000, 3000, 10000];
const COST_BUCKETS = [0.001, 0.01, 0.05, 0.1, 0.5, 1, 5];

export const m = {
  // === traceforge.request.* ===
  requestCount: meter.createCounter('traceforge.request.count', {
    description: 'Total /v1/ask requests handled by orchestrator',
  }),

  requestLatencyMs: meter.createHistogram('traceforge.request.latency_ms', {
    description: 'End-to-end orchestrator latency in ms',
    unit: 'ms',
    // Note: OpenTelemetry doesn't support explicit bucket configuration in the API
    // Datadog will use default buckets, but we document the standard here
  }),

  // === traceforge.rag.* ===
  ragLatencyMs: meter.createHistogram('traceforge.rag.latency_ms', {
    description: 'RAG latency in ms',
    unit: 'ms',
  }),

  ragDocsCount: meter.createUpDownCounter('traceforge.rag.docs.count', {
    description: 'Number of documents retrieved by RAG (gauge-like via up/down counter)',
  }),

  // === traceforge.tool.* ===
  toolCalls: meter.createCounter('traceforge.tool.calls', {
    description: 'Total tool calls (successful)',
  }),

  toolErrors: meter.createCounter('traceforge.tool.errors', {
    description: 'Tool call errors',
  }),

  toolLatencyMs: meter.createHistogram('traceforge.tool.latency_ms', {
    description: 'Tool call latency in ms',
    unit: 'ms',
  }),

  // === traceforge.llm.* ===
  llmLatencyMs: meter.createHistogram('traceforge.llm.latency_ms', {
    description: 'LLM generation latency in ms',
    unit: 'ms',
  }),

  llmTokensInput: meter.createCounter('traceforge.llm.tokens.input', {
    description: 'Total input tokens consumed by LLM',
    unit: 'tokens',
  }),

  llmTokensOutput: meter.createCounter('traceforge.llm.tokens.output', {
    description: 'Total output tokens generated by LLM',
    unit: 'tokens',
  }),

  llmCostUsd: meter.createCounter('traceforge.llm.cost.usd', {
    description: 'Estimated LLM cost in USD',
    unit: 'USD',
  }),

  // === traceforge.eval.* ===
  evalScore: meter.createUpDownCounter('traceforge.eval.score', {
    description: 'Evaluation scores (0-1). Use dimension tag: faithfulness | relevance | policy_risk | hallucination | overall',
  }),

  // === traceforge.remediation.* ===
  remediationTriggered: meter.createCounter('traceforge.remediation.triggered', {
    description: 'Remediation actions triggered. Use action tag: SAFE_MODE | FALLBACK_TOOL | CLARIFICATION | RETRY_LLM',
  }),

  // === traceforge.quality.* ===
  qualityOk: meter.createCounter('traceforge.request.quality_ok', {
    description: 'Requests that meet quality threshold (overall score >= 0.75). Used for Response Quality SLO calculation.',
  }),
};

